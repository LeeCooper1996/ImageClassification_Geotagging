{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "psychological-honolulu",
   "metadata": {},
   "source": [
    "# Geo-tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-president",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "binary-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-mirror",
   "metadata": {},
   "source": [
    "#### Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coordinated-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_data(img_folder_path):\n",
    "    img_pair_list=[]\n",
    "    image_pair_path_list=[]\n",
    "    \n",
    "    a_file,a_file_name=[],[]\n",
    "    b_file,b_file_name=[],[]\n",
    "    \n",
    "    for file in tqdm(os.listdir(img_folder_path)):\n",
    "        if file[-5]=='a':\n",
    "            a_file.append(file)\n",
    "            a_file_name.append(img_folder_path+str(file))            \n",
    "        else:\n",
    "            b_file.append(file)\n",
    "            b_file_name.append(img_folder_path+str(file))\n",
    "    a_file.sort()\n",
    "    a_file_name.sort()\n",
    "    b_file.sort()\n",
    "    b_file_name.sort()\n",
    "\n",
    "    for x in range(len(a_file)):\n",
    "        img_pair_list.append([a_file[x],b_file[x]])\n",
    "        image_pair_path_list.append([a_file_name[x],b_file_name[x]])\n",
    "\n",
    "    return img_pair_list,image_pair_path_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-manchester",
   "metadata": {},
   "source": [
    "### Image Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-prize",
   "metadata": {},
   "source": [
    "#### 1. Image Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "endangered-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(image):\n",
    "    gray_img = cv.imread(image,0)\n",
    "    gray_img=cv.cvtColor(image, cv.COLOR_RGB2GRAY)\n",
    "    enh_img_hst = cv.equalizeHist(gray_img)\n",
    "    clahe = cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    enh_img_clahe = clahe.apply(gray_img)\n",
    "    return enh_img_clahe,enh_img_hst,gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proved-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_image(img):\n",
    "    enh_img_clahe,enh_img_hst,gray_img = helper(img)\n",
    "    return gray_img,enh_img_hst,enh_img_clahe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "married-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_helper(gray_img, enh_img_hst, enh_img_clahe):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    rows = 1\n",
    "    columns = 3\n",
    "    res_img = [gray_img, enh_img_hst, enh_img_clahe]\n",
    "    res_img_title = ['Input Image', 'Histogram Equalized', 'Enhanced Histogram Equalized']\n",
    "\n",
    "    #cv.imwrite(f'enh_img_hst{img_id}.png',enh_img_clahe)\n",
    "\n",
    "\n",
    "    for idx in range(rows,columns):\n",
    "        fig.add_subplot(rows, columns, idx+1)\n",
    "        plt.imshow(result_img[idx], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(res_img_title[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chicken-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_detection(img, lower_th = None, upper_th = None):\n",
    "             \n",
    "    # Noise reduction step\n",
    "    img = cv.GaussianBlur(img, (5, 5), 1.4)\n",
    "    \n",
    "    # Calculating the gradients\n",
    "    gx = cv.Sobel(np.float32(img), cv.CV_64F, 1, 0, 3)\n",
    "    gy = cv.Sobel(np.float32(img), cv.CV_64F, 0, 1, 3)\n",
    "      \n",
    "    # Conversion of Cartesian coordinates to polar \n",
    "    mag, ang = cv.cartToPolar(gx, gy, angleInDegrees = True)\n",
    "       \n",
    "    # set the minimum and maximum thresholds as lower and upper \n",
    "    mag_max = np.max(mag)\n",
    "    if not lower_th:lower_th = mag_max * 0.1\n",
    "    if not upper_th:upper_th = mag_max * 0.5\n",
    "      \n",
    "    # getting the dimensions of the input image  \n",
    "    height, width = img.shape\n",
    "       \n",
    "    # Looping through every pixel of the grayscale \n",
    "    # image\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "               \n",
    "            grad_ang = ang[i_y, i_x]\n",
    "            grad_ang = abs(grad_ang-180) if abs(grad_ang)>180 else abs(grad_ang)\n",
    "               \n",
    "            # selecting the neighbours of the target pixel according to the gradient direction\n",
    "            # In the x axis direction\n",
    "            if grad_ang<= 22.5:\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "              \n",
    "            # top right (diagnol-1) direction\n",
    "            elif grad_ang>22.5 and grad_ang<=(22.5 + 45):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y + 1\n",
    "              \n",
    "            # In y-axis direction\n",
    "            elif grad_ang>(22.5 + 45) and grad_ang<=(22.5 + 90):\n",
    "                neighb_1_x, neighb_1_y = i_x, i_y-1\n",
    "                neighb_2_x, neighb_2_y = i_x, i_y + 1\n",
    "              \n",
    "            # top left (diagnol-2) direction\n",
    "            elif grad_ang>(22.5 + 90) and grad_ang<=(22.5 + 135):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y + 1\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y-1\n",
    "              \n",
    "            # Now it restarts the cycle\n",
    "            elif grad_ang>(22.5 + 135) and grad_ang<=(22.5 + 180):\n",
    "                neighb_1_x, neighb_1_y = i_x-1, i_y\n",
    "                neighb_2_x, neighb_2_y = i_x + 1, i_y\n",
    "               \n",
    "            # Non-maximum suppression step\n",
    "            if width>neighb_1_x>= 0 and height>neighb_1_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_1_y, neighb_1_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "                    continue\n",
    "   \n",
    "            if width>neighb_2_x>= 0 and height>neighb_2_y>= 0:\n",
    "                if mag[i_y, i_x]<mag[neighb_2_y, neighb_2_x]:\n",
    "                    mag[i_y, i_x]= 0\n",
    "   \n",
    "    lower_ids = np.zeros_like(img)\n",
    "    upper_ids = np.zeros_like(img)              \n",
    "    ids = np.zeros_like(img)\n",
    "       \n",
    "    # double thresholding step\n",
    "    for i_x in range(width):\n",
    "        for i_y in range(height):\n",
    "              \n",
    "            grad_mag = mag[i_y, i_x]\n",
    "              \n",
    "            if grad_mag < lower_th:\n",
    "                mag[i_y, i_x]= 0\n",
    "            elif upper_th > grad_mag>= lower_th:\n",
    "                ids[i_y, i_x]= 1\n",
    "            else:\n",
    "                ids[i_y, i_x]= 2\n",
    "    #plt.imshow(mag, cmap='gray')      \n",
    "    # returning the magnitude of gradients of edges\n",
    "    return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "presidential-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_edge_helper(gray_img, enh_img_clahe, canny_img_clahe):\n",
    "    result_img = [gray_img, enh_img_clahe, canny_img_clahe]\n",
    "    result_img_title = ['Input Image', 'Enhanced Image', 'Detected Edges']\n",
    "\n",
    "    # create figure\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "\n",
    "    # setting values to rows and column variables\n",
    "    rows = 1\n",
    "    columns = 3\n",
    "\n",
    "    for idx in range(columns):\n",
    "        fig.add_subplot(rows, columns, idx+1)\n",
    "        plt.imshow(result_img[idx], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(result_img_title[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "functional-things",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:00<00:00, 124045.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Dataset/1-20_New/0_a.npy\n",
      "./Dataset/1-20_New/0_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/10_a.npy\n",
      "./Dataset/1-20_New/10_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/11_a.npy\n",
      "./Dataset/1-20_New/11_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/13_a.npy\n",
      "./Dataset/1-20_New/13_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/15_a.npy\n",
      "./Dataset/1-20_New/15_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/16_a.npy\n",
      "./Dataset/1-20_New/16_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/17_a.npy\n",
      "./Dataset/1-20_New/17_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/19_a.npy\n",
      "./Dataset/1-20_New/19_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/1_a.npy\n",
      "./Dataset/1-20_New/1_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/20_a.npy\n",
      "./Dataset/1-20_New/20_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/21_a.npy\n",
      "./Dataset/1-20_New/21_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/22_a.npy\n",
      "./Dataset/1-20_New/22_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/23_a.npy\n",
      "./Dataset/1-20_New/23_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/24_a.npy\n",
      "./Dataset/1-20_New/24_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/25_a.npy\n",
      "./Dataset/1-20_New/25_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/27_a.npy\n",
      "./Dataset/1-20_New/27_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/28_a.npy\n",
      "./Dataset/1-20_New/28_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/29_a.npy\n",
      "./Dataset/1-20_New/29_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/2_a.npy\n",
      "./Dataset/1-20_New/2_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/4_a.npy\n",
      "./Dataset/1-20_New/4_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/5_a.npy\n",
      "./Dataset/1-20_New/5_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/6_a.npy\n",
      "./Dataset/1-20_New/6_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/8_a.npy\n",
      "./Dataset/1-20_New/8_b.npy\n",
      "\n",
      "\n",
      "./Dataset/1-20_New/9_a.npy\n",
      "./Dataset/1-20_New/9_b.npy\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess(img_folder_path):\n",
    "    img_pair_list,image_pair_path_list=input_data(img_folder_path)\n",
    "    \n",
    "    for pair in image_pair_path_list:\n",
    "        #print(pair)\n",
    "        for img_path in pair:\n",
    "            print(img_path)\n",
    "            data_array = np.load(img_path)\n",
    "            img = Image.fromarray(data_array, 'RGB')\n",
    "            \n",
    "            #gray_img,enh_img_hst,enh_img_clahe=enhance_image(img_path)\n",
    "            #print(gray_img,enh_img_hst,enh_img_clahe)\n",
    "            #plot_helper(gray_img, enh_img_hst, enh_img_clahe)\n",
    "            \n",
    "            #canny_gray_img = edge_detection(gray_img)\n",
    "            #canny_img_hist = edge_detection(enh_img_hst)\n",
    "            #canny_img_clahe = edge_detection(enh_img_clahe)\n",
    "            \n",
    "            #plot_edge_helper(gray_img, enh_img_clahe, canny_img_clahe)\n",
    "        print(\"\\n\")\n",
    "preprocess('./Dataset/1-20_New/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-ratio",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
